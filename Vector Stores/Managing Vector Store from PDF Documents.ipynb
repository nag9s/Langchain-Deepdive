{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Vector Store from PDF Documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 38\n",
      "Total document chunks: 201\n",
      "\n",
      "--- Retrieved Documents ---\n",
      "Total documents retrieved: 5\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 1:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/dietary supplements.pdf\n",
      "\n",
      "Content:\n",
      "supplements mean products that are concentrated sources of vitamins, minerals, or other\n",
      "substances with a nutritional or physiological effect (e.g., amino acids, essential fatty acids,\n",
      "probiotics, plants, and herbal extracts) intended to supplement the regular diet. Dietary\n",
      "supplements are produced in the form of capsules, tablets, pills, and other similar forms,\n",
      "designed to be taken in measured small unit quantities [1,2]. Dietary supplements, despite\n",
      "their route of administration and drug-like... [truncated]\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 2:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/health supplements.pdf\n",
      "\n",
      "Content:\n",
      "women consuming isoflavone supplements (59) and, given the clear evidence of \n",
      "estrogenicity, there is a likelihood of increased risk of estrogen sensitive cancers in \n",
      "consumers of these products.\n",
      "WEIGHT-LOSS, SPORTS, AND BODYBUILDING SUPPLEMENTS\n",
      "As more and more of the world population becomes overweight and obese, there is a huge \n",
      "market for weight-loss products, including dietary supplements. Among military service \n",
      "members, athletes and bodybuilders it is also common to ingest dietary sports ... [truncated]\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 3:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/health supplements.pdf\n",
      "\n",
      "Content:\n",
      "component of Geranium plants, e.g. as geranium extract (71). However, the presence of \n",
      "DMAA in plants has not been verified, leading to the conclusion that DMAA in supplements \n",
      "is generated by chemical synthesis (72). DMAA has further been banned as a performance \n",
      "enhancing drug by the World Anti-Doping Agency (73). One version of the weight-loss \n",
      "supplement OxyELITE Pro from USPlabs, LLC contained the compound 1,3-\n",
      "dimethylamylamine (DMAA) in addition to ingredients such as caffeine, Bauhinia p... [truncated]\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 4:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/nutraceuticals research.pdf\n",
      "\n",
      "Content:\n",
      "a beneficial effect, and they often refer to substances or pre- or\n",
      "probiotics, not to a phytocomplex itself, as promoting a\n",
      "beneﬁcial health effect [20, 38].\n",
      "In contrast, a completely different scenario exists for food\n",
      "supplements (concentrated sources of nutrients or other\n",
      "substances) added to a normal diet that can have a nutritional\n",
      "or\n",
      "physiological\n",
      "effect.\n",
      "Directive\n",
      "2002/46/EC\n",
      "proposed\n",
      "harmonized rules on these products with the aim of\n",
      "protecting consumers against potential health risks and\n",
      "... [truncated]\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 5:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/nutraceuticals research.pdf\n",
      "\n",
      "Content:\n",
      "(FAO) and the World Health Organization (WHO) in the\n",
      "Codex Alimentarius (FAO/WHO 1992). This collection of docu-\n",
      "ments contains general internationally recognized guidelines\n",
      "that establish rules for producing and marketing foodstuffs\n",
      "and their derivatives. Many countries use these guidelines,\n",
      "which deﬁne health claims in terms of: (i) nutrient function;\n",
      "(ii) enhanced function; and (iii) reduction of risk [44, 45].\n",
      "Speciﬁcally, the nutrient function claim, which is deﬁned\n",
      "as “the claim that descr... [truncated]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import warnings\n",
    "import tiktoken\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Document Loading Libraries\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "def load_pdf_documents(directory):\n",
    "    \"\"\"\n",
    "    Load PDF documents from a specified directory.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Path to the directory containing PDF files\n",
    "    \n",
    "    Returns:\n",
    "        list: List of loaded documents\n",
    "    \"\"\"\n",
    "    pdfs = []\n",
    "    docs = []\n",
    "    \n",
    "    # Find all PDF files in the specified directory\n",
    "    for root, _, files in os.walk(directory):\n",
    "        pdfs.extend([os.path.join(root, file) for file in files if file.endswith(\".pdf\")])\n",
    "    \n",
    "    # Load each PDF document\n",
    "    for pdf in pdfs:\n",
    "        loader = PyMuPDFLoader(pdf)\n",
    "        docs.extend(loader.load())\n",
    "    \n",
    "    return docs\n",
    "\n",
    "def chunk_documents(docs, chunk_size=1000, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    Split documents into smaller chunks.\n",
    "    \n",
    "    Args:\n",
    "        docs (list): List of documents to chunk\n",
    "        chunk_size (int): Size of each document chunk\n",
    "        chunk_overlap (int): Overlap between chunks\n",
    "    \n",
    "    Returns:\n",
    "        list: List of document chunks\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, \n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return text_splitter.split_documents(docs)\n",
    "\n",
    "def create_vector_store(chunks, embedding_model='nomic-embed-text', base_url='http://localhost:11434'):\n",
    "    \"\"\"\n",
    "    Create a vector store from document chunks.\n",
    "    \n",
    "    Args:\n",
    "        chunks (list): List of document chunks\n",
    "        embedding_model (str): Name of the embedding model\n",
    "        base_url (str): Base URL for Ollama embeddings\n",
    "    \n",
    "    Returns:\n",
    "        FAISS: Vector store with embedded documents\n",
    "    \"\"\"\n",
    "    # Initialize embeddings\n",
    "    embeddings = OllamaEmbeddings(model=embedding_model, base_url=base_url)\n",
    "    \n",
    "    # Create vector embedding\n",
    "    vector = embeddings.embed_query(\"Hello World\")\n",
    "    \n",
    "    # Create FAISS index\n",
    "    index = faiss.IndexFlatL2(len(vector))\n",
    "    vector_store = FAISS(\n",
    "        embedding_function=embeddings,\n",
    "        index=index,\n",
    "        docstore=InMemoryDocstore(),\n",
    "        index_to_docstore_id={},\n",
    "    )\n",
    "    \n",
    "    # Add documents to vector store\n",
    "    vector_store.add_documents(documents=chunks)\n",
    "    \n",
    "    return vector_store\n",
    "def print_retrieved_docs(retrieved_docs, max_length=500):\n",
    "    \"\"\"\n",
    "    Print retrieved documents in a clean, readable format.\n",
    "    \n",
    "    Args:\n",
    "        retrieved_docs (list): List of retrieved documents\n",
    "        max_length (int): Maximum length of content to display\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Retrieved Documents ---\")\n",
    "    print(f\"Total documents retrieved: {len(retrieved_docs)}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, doc in enumerate(retrieved_docs, 1):\n",
    "        print(f\"\\nDocument {i}:\")\n",
    "        print(f\"Score: {doc.metadata.get('score', 'N/A')}\")\n",
    "        print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        \n",
    "        # Truncate content if it's too long\n",
    "        content = doc.page_content\n",
    "        if len(content) > max_length:\n",
    "            content = content[:max_length] + \"... [truncated]\"\n",
    "        \n",
    "        print(\"\\nContent:\")\n",
    "        print(content)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Main function to orchestrate document processing and vector store creation.\n",
    "    \"\"\"\n",
    "    # Suppress warnings (optional)\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # Load PDF documents\n",
    "    docs = load_pdf_documents(\"../dataset/health_docs\")\n",
    "    \n",
    "    # Optional: Check document count and content\n",
    "    print(f\"Total documents loaded: {len(docs)}\")\n",
    "    \n",
    "    # Chunk documents\n",
    "    chunks = chunk_documents(docs)\n",
    "    print(f\"Total document chunks: {len(chunks)}\")\n",
    "    \n",
    "    # Optional: Tokenization check\n",
    "    # encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "    # token_lengths = [len(encoding.encode(chunk.page_content)) for chunk in chunks[:3]]\n",
    "    # print(f\"Token lengths of first 3 chunks: {token_lengths}\")\n",
    "    \n",
    "    # Create vector store\n",
    "    vector_store = create_vector_store(chunks)\n",
    "    \n",
    "    # Example retrieval\n",
    "    question = \"What nutritional supplements support muscle protein synthesis?\"\n",
    "    retrieved_docs = vector_store.search(query=question, k=5, search_type=\"similarity\")\n",
    "\n",
    "    print_retrieved_docs(retrieved_docs)\n",
    "    \n",
    "    # Optional: Save vector store\n",
    "    db_name = \"../health_docs\"\n",
    "    vector_store.save_local(db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
