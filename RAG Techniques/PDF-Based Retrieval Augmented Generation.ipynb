{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF-Based Retrieval Augmented Generation (RAG): Intelligent Document Querying\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates the implementation of a Retrieval Augmented Generation (RAG) pipeline using PDF documents, showcasing how to combine document retrieval with intelligent language model responses. The guide provides a practical approach to creating context-aware, document-grounded question-answering systems.\n",
    "\n",
    "## Key Features:\n",
    "- Semantic document retrieval\n",
    "- Context-aware response generation\n",
    "- PDF-based knowledge querying\n",
    "- Intelligent information extraction\n",
    "- Flexible RAG pipeline construction\n",
    "\n",
    "## Technologies Used:\n",
    "- Ollama Language Models\n",
    "- FAISS Vector Store\n",
    "- Semantic Retrieval\n",
    "- Prompt Engineering\n",
    "- Context-Based Generation\n",
    "\n",
    "## Use Cases:\n",
    "- Intelligent document querying\n",
    "- Medical research information extraction\n",
    "- Technical documentation analysis\n",
    "- Contextual question answering\n",
    "- Knowledge base exploration\n",
    "\n",
    "## Activities Covered in This Notebook\n",
    "\n",
    "1. **Vector Store Retrieval**  \n",
    "    - Loading pre-indexed document vectors\n",
    "    - Configuring semantic search parameters\n",
    "    - Retrieving most relevant document chunks\n",
    "\n",
    "2. **RAG Pipeline Construction**  \n",
    "    - Designing context-aware prompt templates\n",
    "    - Integrating retriever with language model\n",
    "    - Creating flexible generation pipeline\n",
    "\n",
    "3. **Intelligent Querying**  \n",
    "    - Performing semantic search\n",
    "    - Retrieving contextually relevant documents\n",
    "    - Generating informed responses\n",
    "\n",
    "4. **Response Generation**  \n",
    "    - Using retrieved context to ground LLM responses\n",
    "    - Implementing fallback mechanisms\n",
    "    - Ensuring response relevance\n",
    "\n",
    "5. **Error Handling and Robustness**  \n",
    "    - Managing retrieval and generation exceptions\n",
    "    - Providing clear user feedback\n",
    "    - Ensuring pipeline reliability\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "This notebook provides a foundational implementation of RAG techniques. For more advanced, practical examples, please refer langchain documentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 38\n",
      "Total document chunks: 201\n",
      "\n",
      "--- Retrieved Documents ---\n",
      "Total documents retrieved: 5\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 1:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/dietary supplements.pdf\n",
      "\n",
      "Content:\n",
      "supplements mean products that are concentrated sources of vitamins, minerals, or other\n",
      "substances with a nutritional or physiological effect (e.g., amino acids, essential fatty acids,\n",
      "probiotics, plants, and herbal extracts) intended to supplement the regular diet. Dietary\n",
      "supplements are produced in the form of capsules, tablets, pills, and other similar forms,\n",
      "designed to be taken in measured small unit quantities [1,2]. Dietary supplements, despite\n",
      "their route of administration and drug-like... [truncated]\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 2:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/health supplements.pdf\n",
      "\n",
      "Content:\n",
      "women consuming isoflavone supplements (59) and, given the clear evidence of \n",
      "estrogenicity, there is a likelihood of increased risk of estrogen sensitive cancers in \n",
      "consumers of these products.\n",
      "WEIGHT-LOSS, SPORTS, AND BODYBUILDING SUPPLEMENTS\n",
      "As more and more of the world population becomes overweight and obese, there is a huge \n",
      "market for weight-loss products, including dietary supplements. Among military service \n",
      "members, athletes and bodybuilders it is also common to ingest dietary sports ... [truncated]\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 3:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/health supplements.pdf\n",
      "\n",
      "Content:\n",
      "component of Geranium plants, e.g. as geranium extract (71). However, the presence of \n",
      "DMAA in plants has not been verified, leading to the conclusion that DMAA in supplements \n",
      "is generated by chemical synthesis (72). DMAA has further been banned as a performance \n",
      "enhancing drug by the World Anti-Doping Agency (73). One version of the weight-loss \n",
      "supplement OxyELITE Pro from USPlabs, LLC contained the compound 1,3-\n",
      "dimethylamylamine (DMAA) in addition to ingredients such as caffeine, Bauhinia p... [truncated]\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 4:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/nutraceuticals research.pdf\n",
      "\n",
      "Content:\n",
      "a beneficial effect, and they often refer to substances or pre- or\n",
      "probiotics, not to a phytocomplex itself, as promoting a\n",
      "beneﬁcial health effect [20, 38].\n",
      "In contrast, a completely different scenario exists for food\n",
      "supplements (concentrated sources of nutrients or other\n",
      "substances) added to a normal diet that can have a nutritional\n",
      "or\n",
      "physiological\n",
      "effect.\n",
      "Directive\n",
      "2002/46/EC\n",
      "proposed\n",
      "harmonized rules on these products with the aim of\n",
      "protecting consumers against potential health risks and\n",
      "... [truncated]\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 5:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/nutraceuticals research.pdf\n",
      "\n",
      "Content:\n",
      "(FAO) and the World Health Organization (WHO) in the\n",
      "Codex Alimentarius (FAO/WHO 1992). This collection of docu-\n",
      "ments contains general internationally recognized guidelines\n",
      "that establish rules for producing and marketing foodstuffs\n",
      "and their derivatives. Many countries use these guidelines,\n",
      "which deﬁne health claims in terms of: (i) nutrient function;\n",
      "(ii) enhanced function; and (iii) reduction of risk [44, 45].\n",
      "Speciﬁcally, the nutrient function claim, which is deﬁned\n",
      "as “the claim that descr... [truncated]\n",
      "--------------------------------------------------\n",
      "Vector store saved to ../health_docs.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import warnings\n",
    "import tiktoken\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Document Loading Libraries\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "def load_pdf_documents(directory):\n",
    "    \"\"\"\n",
    "    Load PDF documents from a specified directory.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Path to the directory containing PDF files\n",
    "    \n",
    "    Returns:\n",
    "        list: List of loaded documents\n",
    "    \"\"\"\n",
    "    pdfs = []\n",
    "    docs = []\n",
    "    \n",
    "    # Find all PDF files in the specified directory\n",
    "    for root, _, files in os.walk(directory):\n",
    "        pdfs.extend([os.path.join(root, file) for file in files if file.endswith(\".pdf\")])\n",
    "    \n",
    "    # Load each PDF document\n",
    "    for pdf in pdfs:\n",
    "        loader = PyMuPDFLoader(pdf)\n",
    "        docs.extend(loader.load())\n",
    "    \n",
    "    return docs\n",
    "\n",
    "def chunk_documents(docs, chunk_size=1000, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    Split documents into smaller chunks.\n",
    "    \n",
    "    Args:\n",
    "        docs (list): List of documents to chunk\n",
    "        chunk_size (int): Size of each document chunk\n",
    "        chunk_overlap (int): Overlap between chunks\n",
    "    \n",
    "    Returns:\n",
    "        list: List of document chunks\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, \n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return text_splitter.split_documents(docs)\n",
    "\n",
    "def create_vector_store(chunks, embedding_model='nomic-embed-text', base_url='http://localhost:11434'):\n",
    "    \"\"\"\n",
    "    Create a vector store from document chunks.\n",
    "    \n",
    "    Args:\n",
    "        chunks (list): List of document chunks\n",
    "        embedding_model (str): Name of the embedding model\n",
    "        base_url (str): Base URL for Ollama embeddings\n",
    "    \n",
    "    Returns:\n",
    "        FAISS: Vector store with embedded documents\n",
    "    \"\"\"\n",
    "    # Initialize embeddings\n",
    "    embeddings = OllamaEmbeddings(model=embedding_model, base_url=base_url)\n",
    "    \n",
    "    # Create vector embedding\n",
    "    vector = embeddings.embed_query(\"Hello World\")\n",
    "    \n",
    "    # Create FAISS index\n",
    "    index = faiss.IndexFlatL2(len(vector))\n",
    "    vector_store = FAISS(\n",
    "        embedding_function=embeddings,\n",
    "        index=index,\n",
    "        docstore=InMemoryDocstore(),\n",
    "        index_to_docstore_id={},\n",
    "    )\n",
    "    \n",
    "    # Add documents to vector store\n",
    "    vector_store.add_documents(documents=chunks)\n",
    "    \n",
    "    return vector_store\n",
    "def print_retrieved_docs(retrieved_docs, max_length=500):\n",
    "    \"\"\"\n",
    "    Print retrieved documents in a clean, readable format.\n",
    "    \n",
    "    Args:\n",
    "        retrieved_docs (list): List of retrieved documents\n",
    "        max_length (int): Maximum length of content to display\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Retrieved Documents ---\")\n",
    "    print(f\"Total documents retrieved: {len(retrieved_docs)}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, doc in enumerate(retrieved_docs, 1):\n",
    "        print(f\"\\nDocument {i}:\")\n",
    "        print(f\"Score: {doc.metadata.get('score', 'N/A')}\")\n",
    "        print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        \n",
    "        # Truncate content if it's too long\n",
    "        content = doc.page_content\n",
    "        if len(content) > max_length:\n",
    "            content = content[:max_length] + \"... [truncated]\"\n",
    "        \n",
    "        print(\"\\nContent:\")\n",
    "        print(content)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Main function to orchestrate document processing and vector store creation.\n",
    "    \"\"\"\n",
    "    # Suppress warnings (optional)\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # Load PDF documents\n",
    "    docs = load_pdf_documents(\"../dataset/health_docs\")\n",
    "    \n",
    "    # Optional: Check document count and content\n",
    "    print(f\"Total documents loaded: {len(docs)}\")\n",
    "    \n",
    "    # Chunk documents\n",
    "    chunks = chunk_documents(docs)\n",
    "    print(f\"Total document chunks: {len(chunks)}\")\n",
    "    \n",
    "    # Optional: Tokenization check\n",
    "    # encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "    # token_lengths = [len(encoding.encode(chunk.page_content)) for chunk in chunks[:3]]\n",
    "    # print(f\"Token lengths of first 3 chunks: {token_lengths}\")\n",
    "    \n",
    "    # Create vector store\n",
    "    vector_store = create_vector_store(chunks)\n",
    "    \n",
    "    # Example retrieval\n",
    "    question = \"What nutritional supplements support muscle protein synthesis?\"\n",
    "    retrieved_docs = vector_store.search(query=question, k=5, search_type=\"similarity\")\n",
    "\n",
    "    print_retrieved_docs(retrieved_docs)\n",
    "    \n",
    "    # Optional: Save vector store\n",
    "    db_name = \"../health_docs\"\n",
    "    vector_store.save_local(db_name)\n",
    "    print(f\"Vector store saved to {db_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Query ---\n",
      "Question: What nutritional supplements support muscle protein synthesis?\n",
      "\n",
      "--- Retrieved Documents ---\n",
      "\n",
      "Document 1:\n",
      "supplements mean products that are concentrated sources of vitamins, minerals, or other\n",
      "substances with a nutritional or physiological effect (e.g., amino acids, essential fatty acids,\n",
      "probiotics, plants, and herbal extracts) intended to supplement the regular diet. Dietary\n",
      "supplements are produced in the form of capsules, tablets, pills, and other similar forms,\n",
      "designed to be taken in measured small unit quantities [1,2]. Dietary supplements, despite\n",
      "their route of administration and drug-like...\n",
      "\n",
      "Document 2:\n",
      "women consuming isoflavone supplements (59) and, given the clear evidence of \n",
      "estrogenicity, there is a likelihood of increased risk of estrogen sensitive cancers in \n",
      "consumers of these products.\n",
      "WEIGHT-LOSS, SPORTS, AND BODYBUILDING SUPPLEMENTS\n",
      "As more and more of the world population becomes overweight and obese, there is a huge \n",
      "market for weight-loss products, including dietary supplements. Among military service \n",
      "members, athletes and bodybuilders it is also common to ingest dietary sports ...\n",
      "\n",
      "Document 3:\n",
      "component of Geranium plants, e.g. as geranium extract (71). However, the presence of \n",
      "DMAA in plants has not been verified, leading to the conclusion that DMAA in supplements \n",
      "is generated by chemical synthesis (72). DMAA has further been banned as a performance \n",
      "enhancing drug by the World Anti-Doping Agency (73). One version of the weight-loss \n",
      "supplement OxyELITE Pro from USPlabs, LLC contained the compound 1,3-\n",
      "dimethylamylamine (DMAA) in addition to ingredients such as caffeine, Bauhinia p...\n",
      "\n",
      "Document 4:\n",
      "a beneficial effect, and they often refer to substances or pre- or\n",
      "probiotics, not to a phytocomplex itself, as promoting a\n",
      "beneﬁcial health effect [20, 38].\n",
      "In contrast, a completely different scenario exists for food\n",
      "supplements (concentrated sources of nutrients or other\n",
      "substances) added to a normal diet that can have a nutritional\n",
      "or\n",
      "physiological\n",
      "effect.\n",
      "Directive\n",
      "2002/46/EC\n",
      "proposed\n",
      "harmonized rules on these products with the aim of\n",
      "protecting consumers against potential health risks and\n",
      "...\n",
      "\n",
      "Document 5:\n",
      "(FAO) and the World Health Organization (WHO) in the\n",
      "Codex Alimentarius (FAO/WHO 1992). This collection of docu-\n",
      "ments contains general internationally recognized guidelines\n",
      "that establish rules for producing and marketing foodstuffs\n",
      "and their derivatives. Many countries use these guidelines,\n",
      "which deﬁne health claims in terms of: (i) nutrient function;\n",
      "(ii) enhanced function; and (iii) reduction of risk [44, 45].\n",
      "Speciﬁcally, the nutrient function claim, which is deﬁned\n",
      "as “the claim that descr...\n",
      "\n",
      "--- Generated Answer ---\n",
      "Based on the provided context and regulatory frameworks, I can only provide some general guidance on this topic. However, it's essential to note that the relationship between supplements and muscle protein synthesis (MPS) is complex, and more research is needed to fully understand their interactions.\n",
      "\n",
      "From a nutritional standpoint, several supplements are claimed to support MPS, including:\n",
      "\n",
      "1. Protein powders: Whey protein, casein protein, plant-based proteins like pea or rice protein, and others.\n",
      "2. Creatine monohydrate: A naturally occurring compound found in muscle tissue that is often used by athletes to improve MPS.\n",
      "3. Branched-Chain Amino Acids (BCAAs): Leucine, Isoleucine, and Valine are three amino acids that can stimulate MPS.\n",
      "\n",
      "However, the regulation of these supplements varies across countries and regulatory frameworks. In general, food supplements are subject to guidelines like those established by the FAO/WHO Codex Alimentarius, which emphasize the importance of nutrient function claims rather than health benefits. Nutraceuticals, on the other hand, often have more complex regulatory systems.\n",
      "\n",
      "Regarding specific ingredients that support MPS, some examples include:\n",
      "\n",
      "* Creatine: A naturally occurring compound found in muscle tissue.\n",
      "* Whey protein: A high-quality protein source rich in branched-chain amino acids (BCAAs).\n",
      "* BCAAs: Leucine, Isoleucine, and Valine can stimulate MPS.\n",
      "\n",
      "It's essential to note that individual results may vary, and the effectiveness of these supplements for MPS support is still being researched. Additionally, it's crucial to consult with a healthcare professional or registered dietitian before adding any supplements to your regimen.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Build RAG pipeline\n",
    "def build_rag_pipeline(retriever, llm, template):\n",
    "    \"\"\"\n",
    "    Build a retrieval-augmented generation (RAG) pipeline.\n",
    "    \n",
    "    Args:\n",
    "        retriever (Retriever): The retriever for fetching relevant documents\n",
    "        llm (ChatOllama): The language model for generation\n",
    "        template (str): The prompt template for the LLM\n",
    "    \n",
    "    Returns:\n",
    "        Runnable: The RAG pipeline\n",
    "    \"\"\"\n",
    "    # Initialize chat prompt from template\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # Format retrieved documents\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    # Build the RAG pipeline\n",
    "    rag_pipeline = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return rag_pipeline\n",
    "\n",
    "def main():\n",
    "    # Define database name and embedding model\n",
    "    db_name = \"../health_docs\"  # Update with your actual path\n",
    "    embedding_model = \"nomic-embed-text\"  # or \"nomic-embed-text\"\n",
    "\n",
    "    # Load vector store\n",
    "    embeddings = OllamaEmbeddings(model=embedding_model)\n",
    "    vector_store = FAISS.load_local(\n",
    "        db_name, \n",
    "        embeddings=embeddings, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    \n",
    "    # Configure retriever\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5}  # retrieve top 5 most relevant documents\n",
    "    )\n",
    "\n",
    "    # Initialize the language model\n",
    "    ollama_model = ChatOllama(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model='llama3.2:1b',\n",
    "        temperature=0.5,\n",
    "        num_predict=512\n",
    "    )\n",
    "    \n",
    "    # Define the prompt template\n",
    "    template = \"\"\"You are an expert in health and nutrition. \n",
    "    Answer the question based strictly on the following context:\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    If the context does not provide sufficient information, clearly state that you cannot provide a comprehensive answer based on the available information.\"\"\"\n",
    "\n",
    "    # Build the RAG pipeline\n",
    "    rag_pipeline = build_rag_pipeline(retriever, ollama_model, template)\n",
    "    \n",
    "    # Example RAG-based retrieval and generation\n",
    "    question = \"What nutritional supplements support muscle protein synthesis?\"\n",
    "    try:\n",
    "        print(\"\\n--- Query ---\")\n",
    "        print(f\"Question: {question}\")\n",
    "        \n",
    "        # Retrieve documents first\n",
    "        retrieved_docs = retriever.invoke(question)\n",
    "        \n",
    "        # Print retrieved documents (optional)\n",
    "        print(\"\\n--- Retrieved Documents ---\")\n",
    "        for i, doc in enumerate(retrieved_docs, 1):\n",
    "            print(f\"\\nDocument {i}:\")\n",
    "            print(doc.page_content[:500] + \"...\")  # Print first 500 characters\n",
    "        \n",
    "        # Invoke RAG pipeline\n",
    "        result = rag_pipeline.invoke(question)\n",
    "        \n",
    "        print(\"\\n--- Generated Answer ---\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during RAG process: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
