{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF-Based Retrieval Augmented Generation (RAG): Intelligent Document Querying\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates the implementation of a Retrieval Augmented Generation (RAG) pipeline using PDF documents, showcasing how to combine document retrieval with intelligent language model responses. The guide provides a practical approach to creating context-aware, document-grounded question-answering systems.\n",
    "\n",
    "## Key Features:\n",
    "- Semantic document retrieval\n",
    "- Context-aware response generation\n",
    "- PDF-based knowledge querying\n",
    "- Intelligent information extraction\n",
    "- Flexible RAG pipeline construction\n",
    "\n",
    "## Technologies Used:\n",
    "- Ollama Language Models\n",
    "- FAISS Vector Store\n",
    "- Semantic Retrieval\n",
    "- Prompt Engineering\n",
    "- Context-Based Generation\n",
    "\n",
    "## Use Cases:\n",
    "- Intelligent document querying\n",
    "- Medical research information extraction\n",
    "- Technical documentation analysis\n",
    "- Contextual question answering\n",
    "- Knowledge base exploration\n",
    "\n",
    "## Activities Covered in This Notebook\n",
    "\n",
    "1. **Vector Store Retrieval**  \n",
    "    - Loading pre-indexed document vectors\n",
    "    - Configuring semantic search parameters\n",
    "    - Retrieving most relevant document chunks\n",
    "\n",
    "2. **RAG Pipeline Construction**  \n",
    "    - Designing context-aware prompt templates\n",
    "    - Integrating retriever with language model\n",
    "    - Creating flexible generation pipeline\n",
    "\n",
    "3. **Intelligent Querying**  \n",
    "    - Performing semantic search\n",
    "    - Retrieving contextually relevant documents\n",
    "    - Generating informed responses\n",
    "\n",
    "4. **Response Generation**  \n",
    "    - Using retrieved context to ground LLM responses\n",
    "    - Implementing fallback mechanisms\n",
    "    - Ensuring response relevance\n",
    "\n",
    "5. **Error Handling and Robustness**  \n",
    "    - Managing retrieval and generation exceptions\n",
    "    - Providing clear user feedback\n",
    "    - Ensuring pipeline reliability\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "This notebook provides a foundational implementation of RAG techniques. For more advanced, practical examples, please refer langchain documentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /home/labuser/.local/lib/python3.12/site-packages (from langchain_community) (0.3.49)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from langchain_community) (0.3.22)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from langchain_community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from langchain_community) (3.11.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/labuser/.local/lib/python3.12/site-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /home/labuser/.local/lib/python3.12/site-packages (from langchain_community) (0.1.147)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.3.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /home/labuser/.local/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (0.3.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/labuser/.local/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (2.11.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/labuser/.local/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (4.13.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/labuser/.local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: sniffio in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /home/labuser/.local/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/labuser/.local/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (0.4.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/labuser/.conda/envs/langchain/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 38\n",
      "Total document chunks: 201\n",
      "\n",
      "--- Retrieved Documents ---\n",
      "Total documents retrieved: 5\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 1:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/dietary supplements.pdf\n",
      "\n",
      "Content:\n",
      "supplements mean products that are concentrated sources of vitamins, minerals, or other\n",
      "substances with a nutritional or physiological effect (e.g., amino acids, essential fatty acids,\n",
      "probiotics, plants, and herbal extracts) intended to supplement the regular diet. Dietary\n",
      "supplements are produced in the form of capsules, tablets, pills, and other similar forms,\n",
      "designed to be taken in measured small unit quantities [1,2]. Dietary supplements, despite\n",
      "their route of administration and drug-like... [truncated]\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 2:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/health supplements.pdf\n",
      "\n",
      "Content:\n",
      "women consuming isoflavone supplements (59) and, given the clear evidence of \n",
      "estrogenicity, there is a likelihood of increased risk of estrogen sensitive cancers in \n",
      "consumers of these products.\n",
      "WEIGHT-LOSS, SPORTS, AND BODYBUILDING SUPPLEMENTS\n",
      "As more and more of the world population becomes overweight and obese, there is a huge \n",
      "market for weight-loss products, including dietary supplements. Among military service \n",
      "members, athletes and bodybuilders it is also common to ingest dietary sports ... [truncated]\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 3:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/health supplements.pdf\n",
      "\n",
      "Content:\n",
      "component of Geranium plants, e.g. as geranium extract (71). However, the presence of \n",
      "DMAA in plants has not been verified, leading to the conclusion that DMAA in supplements \n",
      "is generated by chemical synthesis (72). DMAA has further been banned as a performance \n",
      "enhancing drug by the World Anti-Doping Agency (73). One version of the weight-loss \n",
      "supplement OxyELITE Pro from USPlabs, LLC contained the compound 1,3-\n",
      "dimethylamylamine (DMAA) in addition to ingredients such as caffeine, Bauhinia p... [truncated]\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 4:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/nutraceuticals research.pdf\n",
      "\n",
      "Content:\n",
      "a beneficial effect, and they often refer to substances or pre- or\n",
      "probiotics, not to a phytocomplex itself, as promoting a\n",
      "beneﬁcial health effect [20, 38].\n",
      "In contrast, a completely different scenario exists for food\n",
      "supplements (concentrated sources of nutrients or other\n",
      "substances) added to a normal diet that can have a nutritional\n",
      "or\n",
      "physiological\n",
      "effect.\n",
      "Directive\n",
      "2002/46/EC\n",
      "proposed\n",
      "harmonized rules on these products with the aim of\n",
      "protecting consumers against potential health risks and\n",
      "... [truncated]\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 5:\n",
      "Score: N/A\n",
      "Source: ../dataset/health_docs/nutraceuticals research.pdf\n",
      "\n",
      "Content:\n",
      "(FAO) and the World Health Organization (WHO) in the\n",
      "Codex Alimentarius (FAO/WHO 1992). This collection of docu-\n",
      "ments contains general internationally recognized guidelines\n",
      "that establish rules for producing and marketing foodstuffs\n",
      "and their derivatives. Many countries use these guidelines,\n",
      "which deﬁne health claims in terms of: (i) nutrient function;\n",
      "(ii) enhanced function; and (iii) reduction of risk [44, 45].\n",
      "Speciﬁcally, the nutrient function claim, which is deﬁned\n",
      "as “the claim that descr... [truncated]\n",
      "--------------------------------------------------\n",
      "Vector store saved to ../health_docs.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import warnings\n",
    "import tiktoken\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Document Loading Libraries\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "def load_pdf_documents(directory):\n",
    "    \"\"\"\n",
    "    Load PDF documents from a specified directory.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Path to the directory containing PDF files\n",
    "    \n",
    "    Returns:\n",
    "        list: List of loaded documents\n",
    "    \"\"\"\n",
    "    pdfs = []\n",
    "    docs = []\n",
    "    \n",
    "    # Find all PDF files in the specified directory\n",
    "    for root, _, files in os.walk(directory):\n",
    "        pdfs.extend([os.path.join(root, file) for file in files if file.endswith(\".pdf\")])\n",
    "    \n",
    "    # Load each PDF document\n",
    "    for pdf in pdfs:\n",
    "        loader = PyMuPDFLoader(pdf)\n",
    "        docs.extend(loader.load())\n",
    "    \n",
    "    return docs\n",
    "\n",
    "def chunk_documents(docs, chunk_size=1000, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    Split documents into smaller chunks.\n",
    "    \n",
    "    Args:\n",
    "        docs (list): List of documents to chunk\n",
    "        chunk_size (int): Size of each document chunk\n",
    "        chunk_overlap (int): Overlap between chunks\n",
    "    \n",
    "    Returns:\n",
    "        list: List of document chunks\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, \n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return text_splitter.split_documents(docs)\n",
    "\n",
    "def create_vector_store(chunks, embedding_model='nomic-embed-text', base_url='http://localhost:11434'):\n",
    "    \"\"\"\n",
    "    Create a vector store from document chunks.\n",
    "    \n",
    "    Args:\n",
    "        chunks (list): List of document chunks\n",
    "        embedding_model (str): Name of the embedding model\n",
    "        base_url (str): Base URL for Ollama embeddings\n",
    "    \n",
    "    Returns:\n",
    "        FAISS: Vector store with embedded documents\n",
    "    \"\"\"\n",
    "    # Initialize embeddings\n",
    "    embeddings = OllamaEmbeddings(model=embedding_model, base_url=base_url)\n",
    "    \n",
    "    # Create vector embedding\n",
    "    vector = embeddings.embed_query(\"Hello World\")\n",
    "    \n",
    "    # Create FAISS index\n",
    "    index = faiss.IndexFlatL2(len(vector))\n",
    "    vector_store = FAISS(\n",
    "        embedding_function=embeddings,\n",
    "        index=index,\n",
    "        docstore=InMemoryDocstore(),\n",
    "        index_to_docstore_id={},\n",
    "    )\n",
    "    \n",
    "    # Add documents to vector store\n",
    "    vector_store.add_documents(documents=chunks)\n",
    "    \n",
    "    return vector_store\n",
    "def print_retrieved_docs(retrieved_docs, max_length=500):\n",
    "    \"\"\"\n",
    "    Print retrieved documents in a clean, readable format.\n",
    "    \n",
    "    Args:\n",
    "        retrieved_docs (list): List of retrieved documents\n",
    "        max_length (int): Maximum length of content to display\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Retrieved Documents ---\")\n",
    "    print(f\"Total documents retrieved: {len(retrieved_docs)}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, doc in enumerate(retrieved_docs, 1):\n",
    "        print(f\"\\nDocument {i}:\")\n",
    "        print(f\"Score: {doc.metadata.get('score', 'N/A')}\")\n",
    "        print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        \n",
    "        # Truncate content if it's too long\n",
    "        content = doc.page_content\n",
    "        if len(content) > max_length:\n",
    "            content = content[:max_length] + \"... [truncated]\"\n",
    "        \n",
    "        print(\"\\nContent:\")\n",
    "        print(content)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Main function to orchestrate document processing and vector store creation.\n",
    "    \"\"\"\n",
    "    # Suppress warnings (optional)\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # Load PDF documents\n",
    "    docs = load_pdf_documents(\"../dataset/health_docs\")\n",
    "    \n",
    "    # Optional: Check document count and content\n",
    "    print(f\"Total documents loaded: {len(docs)}\")\n",
    "    \n",
    "    # Chunk documents\n",
    "    chunks = chunk_documents(docs)\n",
    "    print(f\"Total document chunks: {len(chunks)}\")\n",
    "    \n",
    "    # Optional: Tokenization check\n",
    "    # encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "    # token_lengths = [len(encoding.encode(chunk.page_content)) for chunk in chunks[:3]]\n",
    "    # print(f\"Token lengths of first 3 chunks: {token_lengths}\")\n",
    "    \n",
    "    # Create vector store\n",
    "    vector_store = create_vector_store(chunks)\n",
    "    \n",
    "    # Example retrieval\n",
    "    question = \"What nutritional supplements support muscle protein synthesis?\"\n",
    "    retrieved_docs = vector_store.search(query=question, k=5, search_type=\"similarity\")\n",
    "\n",
    "    print_retrieved_docs(retrieved_docs)\n",
    "    \n",
    "    # Optional: Save vector store\n",
    "    db_name = \"../health_docs\"\n",
    "    vector_store.save_local(db_name)\n",
    "    print(f\"Vector store saved to {db_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Query ---\n",
      "Question: What nutritional supplements support muscle protein synthesis?\n",
      "\n",
      "--- Retrieved Documents ---\n",
      "\n",
      "Document 1:\n",
      "supplements mean products that are concentrated sources of vitamins, minerals, or other\n",
      "substances with a nutritional or physiological effect (e.g., amino acids, essential fatty acids,\n",
      "probiotics, plants, and herbal extracts) intended to supplement the regular diet. Dietary\n",
      "supplements are produced in the form of capsules, tablets, pills, and other similar forms,\n",
      "designed to be taken in measured small unit quantities [1,2]. Dietary supplements, despite\n",
      "their route of administration and drug-like...\n",
      "\n",
      "Document 2:\n",
      "women consuming isoflavone supplements (59) and, given the clear evidence of \n",
      "estrogenicity, there is a likelihood of increased risk of estrogen sensitive cancers in \n",
      "consumers of these products.\n",
      "WEIGHT-LOSS, SPORTS, AND BODYBUILDING SUPPLEMENTS\n",
      "As more and more of the world population becomes overweight and obese, there is a huge \n",
      "market for weight-loss products, including dietary supplements. Among military service \n",
      "members, athletes and bodybuilders it is also common to ingest dietary sports ...\n",
      "\n",
      "Document 3:\n",
      "component of Geranium plants, e.g. as geranium extract (71). However, the presence of \n",
      "DMAA in plants has not been verified, leading to the conclusion that DMAA in supplements \n",
      "is generated by chemical synthesis (72). DMAA has further been banned as a performance \n",
      "enhancing drug by the World Anti-Doping Agency (73). One version of the weight-loss \n",
      "supplement OxyELITE Pro from USPlabs, LLC contained the compound 1,3-\n",
      "dimethylamylamine (DMAA) in addition to ingredients such as caffeine, Bauhinia p...\n",
      "\n",
      "Document 4:\n",
      "a beneficial effect, and they often refer to substances or pre- or\n",
      "probiotics, not to a phytocomplex itself, as promoting a\n",
      "beneﬁcial health effect [20, 38].\n",
      "In contrast, a completely different scenario exists for food\n",
      "supplements (concentrated sources of nutrients or other\n",
      "substances) added to a normal diet that can have a nutritional\n",
      "or\n",
      "physiological\n",
      "effect.\n",
      "Directive\n",
      "2002/46/EC\n",
      "proposed\n",
      "harmonized rules on these products with the aim of\n",
      "protecting consumers against potential health risks and\n",
      "...\n",
      "\n",
      "Document 5:\n",
      "(FAO) and the World Health Organization (WHO) in the\n",
      "Codex Alimentarius (FAO/WHO 1992). This collection of docu-\n",
      "ments contains general internationally recognized guidelines\n",
      "that establish rules for producing and marketing foodstuffs\n",
      "and their derivatives. Many countries use these guidelines,\n",
      "which deﬁne health claims in terms of: (i) nutrient function;\n",
      "(ii) enhanced function; and (iii) reduction of risk [44, 45].\n",
      "Speciﬁcally, the nutrient function claim, which is deﬁned\n",
      "as “the claim that descr...\n",
      "\n",
      "--- Generated Answer ---\n",
      "Based on the provided context and regulatory framework, it appears that there is limited information available about specific nutritional supplements that directly support muscle protein synthesis (MPS). However, I can provide some general insights and recommendations.\n",
      "\n",
      "Muscle protein synthesis is an essential process for building and repairing muscle tissue. While dietary supplements can play a role in supporting MPS, the evidence is not yet conclusive, and more research is needed to fully understand their effects.\n",
      "\n",
      "That being said, here are some potential nutritional supplements that may support muscle protein synthesis:\n",
      "\n",
      "1. Protein powder: Whey protein, casein protein, or plant-based proteins like pea or rice protein can be effective supplements for building and repairing muscle tissue.\n",
      "2. Creatine monohydrate: This supplement has been extensively studied and is often recommended by fitness professionals to improve MPS and athletic performance.\n",
      "3. Branched-Chain Amino Acids (BCAAs): BCAAs, consisting of leucine, isoleucine, and valine, can help promote MPS and muscle recovery after exercise.\n",
      "\n",
      "However, it's essential to note that the effectiveness of these supplements may vary depending on individual factors such as starting intensity, training experience, and overall nutrition. Additionally, some supplements may have adverse effects or interact with medications.\n",
      "\n",
      "To support muscle protein synthesis, a well-balanced diet that includes adequate protein intake, combined with regular exercise and sufficient rest, is often recommended. Supplements can be used to augment this effort, but their use should be approached with caution and under the guidance of a healthcare professional.\n",
      "\n",
      "In terms of regulatory frameworks, there are guidelines for food supplements in the Codex Alimentarius and the World Health Organization's (WHO) Code of Good Agriculture Practice. However, these regulations do not specifically address nutraceuticals or dietary supplements that support muscle protein synthesis.\n",
      "\n",
      "In summary, while some nutritional supplements may support muscle protein synthesis, more research is needed to fully understand their effects and optimal use. A well-planned diet, combined with regular exercise and sufficient rest, remains the most effective way to support MPS.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Build RAG pipeline\n",
    "def build_rag_pipeline(retriever, llm, template):\n",
    "    \"\"\"\n",
    "    Build a retrieval-augmented generation (RAG) pipeline.\n",
    "    \n",
    "    Args:\n",
    "        retriever (Retriever): The retriever for fetching relevant documents\n",
    "        llm (ChatOllama): The language model for generation\n",
    "        template (str): The prompt template for the LLM\n",
    "    \n",
    "    Returns:\n",
    "        Runnable: The RAG pipeline\n",
    "    \"\"\"\n",
    "    # Initialize chat prompt from template\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # Format retrieved documents\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    # Build the RAG pipeline\n",
    "    rag_pipeline = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return rag_pipeline\n",
    "\n",
    "def main():\n",
    "    # Define database name and embedding model\n",
    "    db_name = \"../health_docs\"  # Update with your actual path\n",
    "    embedding_model = \"nomic-embed-text\"  # or \"nomic-embed-text\"\n",
    "\n",
    "    # Load vector store\n",
    "    embeddings = OllamaEmbeddings(model=embedding_model)\n",
    "    vector_store = FAISS.load_local(\n",
    "        db_name, \n",
    "        embeddings=embeddings, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    \n",
    "    # Configure retriever\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5}  # retrieve top 5 most relevant documents\n",
    "    )\n",
    "\n",
    "    # Initialize the language model\n",
    "    ollama_model = ChatOllama(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model='llama3.2:1b',\n",
    "        temperature=0.5,\n",
    "        num_predict=512\n",
    "    )\n",
    "    \n",
    "    # Define the prompt template\n",
    "    template = \"\"\"You are an expert in health and nutrition. \n",
    "    Answer the question based strictly on the following context:\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    If the context does not provide sufficient information, clearly state that you cannot provide a comprehensive answer based on the available information.\"\"\"\n",
    "\n",
    "    # Build the RAG pipeline\n",
    "    rag_pipeline = build_rag_pipeline(retriever, ollama_model, template)\n",
    "    \n",
    "    # Example RAG-based retrieval and generation\n",
    "    question = \"What nutritional supplements support muscle protein synthesis?\"\n",
    "    try:\n",
    "        print(\"\\n--- Query ---\")\n",
    "        print(f\"Question: {question}\")\n",
    "        \n",
    "        # Retrieve documents first\n",
    "        retrieved_docs = retriever.invoke(question)\n",
    "        \n",
    "        # Print retrieved documents (optional)\n",
    "        print(\"\\n--- Retrieved Documents ---\")\n",
    "        for i, doc in enumerate(retrieved_docs, 1):\n",
    "            print(f\"\\nDocument {i}:\")\n",
    "            print(doc.page_content[:500] + \"...\")  # Print first 500 characters\n",
    "        \n",
    "        # Invoke RAG pipeline\n",
    "        result = rag_pipeline.invoke(question)\n",
    "        \n",
    "        print(\"\\n--- Generated Answer ---\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during RAG process: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
